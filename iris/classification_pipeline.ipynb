{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "403f4123-26d5-4566-bb70-dc1161e38fbc",
    "_uuid": "3d50d40f6b86eaa237a70d02bd4882a6b9bd8ea5"
   },
   "source": [
    "This is a basic example of building a classification pipeline, by which different Classification algorithm can be tried out, and once the pipeline is built hyperparameters tuning can be done usng Cross Validation. \n",
    "\n",
    "I've updated the notebook to follow [ML-mastery's process](https://machinelearningmastery.com/python-machine-learning-mini-course/), which is very useful for getting consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "63b35015-e62e-49f0-be1b-b4a64ef7c979",
    "_uuid": "26c739a37907102bb5eaca6e7e25c84e9990c22b"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "#from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f586fe72-973c-4970-8807-80e30eea9359",
    "_uuid": "3876a252bcee62c69836b76f41942df7a21bb106"
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "53486a0b-4938-4383-97d0-e418fdc7570e",
    "_uuid": "ec0af184051aee38d7dd31b9aa884bc32077a016"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./iris-species/Iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "23fd43c2-5bea-4a9f-9e62-c672e3735f26",
    "_uuid": "cbd968664e88f67f16b758a7d169495451312f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      "Id               150 non-null int64\n",
      "SepalLengthCm    150 non-null float64\n",
      "SepalWidthCm     150 non-null float64\n",
      "PetalLengthCm    150 non-null float64\n",
      "PetalWidthCm     150 non-null float64\n",
      "Species          150 non-null object\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c45c3c97-d752-49dd-9994-671e8bce263e",
    "_uuid": "053edab50d834a909a9a42aeb511c3398c183c16",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cad8f8d3-016d-4c08-baff-895ffd640507",
    "_uuid": "f0a643958884e45c7dc4389f1839bd1a7608820f"
   },
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "788d695f-9de1-4b62-96c7-467789e838b9",
    "_uuid": "a21e875324bc526b2a36c4e3c7717f0c20742f0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7f0161d0b410>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cool visualization from https://www.kaggle.com/benhamner/python-data-visualizations\n",
    "\n",
    "sns.pairplot(data, hue='Species', size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "752c0e94-33b3-4d6f-a506-20548c2c5e9b",
    "_uuid": "f7839d8b08085193c1416c15bee80205aed5bf1c"
   },
   "source": [
    "Petal length and Petal Width are highly correlated, highly correlated features can be omitted in feature selection when working on huge datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "03ec774d-4f5e-4205-937d-c5fe1632fbc9",
    "_uuid": "456641fcd773cbcda6577019a02ec8c1d6fa44a9"
   },
   "source": [
    "## Building the Pipeline\n",
    "\n",
    "Before proceeding 'Species' must be encoded to an integer using ` LabelEncoder()`. *(someone kindly throw light on whether transformations to 'y' can be a part of the pipeline, last time I checked this was an open in issue in sklearn)*\n",
    "\n",
    "We are building a basic pipeline with two steps,\n",
    "\n",
    "* Normalize numerical features with `StandardScaler()`\n",
    "* Run the Classifier, `KNearestClassifier()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "4ca14e95-54cb-4eb5-aa6a-39efa767ec0a",
    "_uuid": "a3a58ac1127e97ca89faca43068351297a5b70ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0              5.1           3.5            1.4           0.2        0\n",
       "1              4.9           3.0            1.4           0.2        0\n",
       "148            6.2           3.4            5.4           2.3        2\n",
       "149            5.9           3.0            5.1           1.8        2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['Species'] = LabelEncoder().fit_transform(data['Species'])\n",
    "data.iloc[[0,1,-2,-1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "63935538-367c-4a97-bca7-273883d60492",
    "_uuid": "449143fc16b1fb0becbbd73094cd381c0be99389"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('normalizer', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('normalizer', StandardScaler()), #Step1 - normalize data\n",
    "    ('clf', LogisticRegression()) #step2 - classifier\n",
    "])\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "fb0ffe4c-0b3e-4d1c-995b-36e77e572e85",
    "_uuid": "e24ebac0c5a2cfdf72d310823423d29a5fbc31b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n",
      "(90,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "#Seperate train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1].values,\n",
    "                                                   data['Species'],\n",
    "                                                   test_size = 0.4,\n",
    "                                                   random_state = 10)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f736944333b82a31b17dc66dbc7d15248991ba9c"
   },
   "source": [
    "### Trying Logistic Regression Classifier\n",
    "\n",
    "Use Cross-validation to test the accuracy of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "7212c7fb-6a3e-481a-87f6-385fc20955f5",
    "_uuid": "a19a6137a1900e1fa8e2c0a4a0e9e4fac706bd98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.00220585,  0.00263977,  0.001616  ]),\n",
       " 'score_time': array([ 0.00113821,  0.00096512,  0.00048399]),\n",
       " 'test_score': array([ 0.83870968,  0.87096774,  0.89285714]),\n",
       " 'train_score': array([ 0.91525424,  0.88135593,  0.88709677])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(pipeline, X_train, y_train)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86751152073732729"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average accuracy of pipeline with Logistic Regression 86.75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8e0d5339-4ef3-4829-8b3d-593a0d06cdb9",
    "_uuid": "ad0ca63ddd355c155e2147f8d6847c63d9195648"
   },
   "source": [
    "## Spot Check Algorithms in the pipeline\n",
    "\n",
    "#### Trying out the following classification algorithms\n",
    "\n",
    "    -LogisticRegression\n",
    "    -Support Vector Machines - linear and rbf\n",
    "    -K-nearest Classifier\n",
    "    -Decision Tree Classifier\n",
    "    -Gradient Bossting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b31a1e71-1a50-4883-8c95-b001efc2f3de",
    "_uuid": "90126f46cc79d4a9f20cc47ceda7a56b186b22c2"
   },
   "source": [
    "The classfier step of the pipeline should be modified to the necessary classifier, I am trying out `SVC()` and `KNearestClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_cell_guid": "50a6f8d9-4c2e-4c4c-be1b-85e3eb60fa9d",
    "_uuid": "bc5639f6ede76482fe483d84ced68951c0d84e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "-----------------------------------\n",
      "score_time  mean  0.0015119711558\n",
      "score_time  std  0.00067293877536\n",
      "test_score  mean  0.867511520737\n",
      "test_score  std  0.0222402952927\n",
      "train_score  mean  0.894568981228\n",
      "train_score  std  0.0148132638848\n",
      "fit_time  mean  0.0037534236908\n",
      "fit_time  std  0.000704138049282\n",
      "-----------------------------------\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "-----------------------------------\n",
      "score_time  mean  0.00143663088481\n",
      "score_time  std  0.000794463423358\n",
      "test_score  mean  0.955837173579\n",
      "test_score  std  0.0144609603562\n",
      "train_score  mean  0.972024785857\n",
      "train_score  std  0.0161765837109\n",
      "fit_time  mean  0.00290767351786\n",
      "fit_time  std  0.000427141876391\n",
      "-----------------------------------\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "-----------------------------------\n",
      "score_time  mean  0.0010560353597\n",
      "score_time  std  0.000237758225304\n",
      "test_score  mean  0.955837173579\n",
      "test_score  std  0.0144609603562\n",
      "train_score  mean  0.972024785857\n",
      "train_score  std  0.0161765837109\n",
      "fit_time  mean  0.00179664293925\n",
      "fit_time  std  0.000163755249664\n",
      "-----------------------------------\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "-----------------------------------\n",
      "score_time  mean  0.00152627627055\n",
      "score_time  std  0.000101975044901\n",
      "test_score  mean  0.945084485407\n",
      "test_score  std  0.0296321685466\n",
      "train_score  mean  0.9779478768\n",
      "train_score  std  0.0156075772305\n",
      "fit_time  mean  0.00177645683289\n",
      "fit_time  std  0.000343372586395\n",
      "-----------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "-----------------------------------\n",
      "score_time  mean  0.000998735427856\n",
      "score_time  std  0.000217147195229\n",
      "test_score  mean  0.956989247312\n",
      "test_score  std  0.0304131948897\n",
      "train_score  mean  1.0\n",
      "train_score  std  0.0\n",
      "fit_time  mean  0.00201265017192\n",
      "fit_time  std  0.000398807384799\n",
      "-----------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "-----------------------------------\n",
      "score_time  mean  0.00187508265177\n",
      "score_time  std  0.000233467700073\n",
      "test_score  mean  0.945084485407\n",
      "test_score  std  0.0135773191472\n",
      "train_score  mean  1.0\n",
      "train_score  std  0.0\n",
      "fit_time  mean  0.0455458958944\n",
      "fit_time  std  0.00287898961813\n",
      "-----------------------------------\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "-----------------------------------\n",
      "score_time  mean  0.000940322875977\n",
      "score_time  std  3.07482948813e-05\n",
      "test_score  mean  0.956989247312\n",
      "test_score  std  0.0304131948897\n",
      "train_score  mean  1.0\n",
      "train_score  std  0.0\n",
      "fit_time  mean  0.175974289576\n",
      "fit_time  std  0.0145697254786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "clfs = []\n",
    "clfs.append(LogisticRegression())\n",
    "clfs.append(SVC())\n",
    "clfs.append(SVC())\n",
    "clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "clfs.append(DecisionTreeClassifier())\n",
    "clfs.append(RandomForestClassifier())\n",
    "clfs.append(GradientBoostingClassifier())\n",
    "\n",
    "for classifier in clfs:\n",
    "    pipeline.set_params(clf = classifier)\n",
    "    scores = cross_validate(pipeline, X_train, y_train)\n",
    "    print '-----------------------------------'\n",
    "    print str(classifier)\n",
    "    print '-----------------------------------'\n",
    "    for key, values in scores.items():\n",
    "            print key,' mean ', values.mean()\n",
    "            print key,' std ', values.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Among the Classifier SVC has the highest accuracy of  95.58%, hence choosing SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d1c4870-62b5-4546-b062-f100ff35507e",
    "_uuid": "b0acacbecaeea4648928802613460a1988f98051"
   },
   "source": [
    "## Cross-Validation and Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2d2ef1c3-e405-4233-95d8-372912be233a",
    "_uuid": "79e0060084bd6ae0c433feef0e704a110b72546a"
   },
   "source": [
    "Cross Validation is the process of finding the best combination of parameters for the model by traning and evaluating the model for each combination of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "36d6eb10-377f-4678-81d5-70a31cc9a181",
    "_uuid": "8465eb9eecdd9e20301fdbf7b1b899a26626c1f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('normalizer', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline.set_params(clf= SVC())\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0eabedc8-93c3-4d65-8754-3571f4879b12",
    "_uuid": "bc8d2c3d48752f578d9d895ba331fcca63c992c4"
   },
   "source": [
    "Trying out different values for parameters solver and regularization Strength 'C' of logistic regression classifier\n",
    "to provide values to a parameter of a step in the pipeline, the syntax is *stepname__parameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_cell_guid": "7178a7b7-48ea-4c82-baa9-084fc46912e5",
    "_uuid": "386e61642e71e4a327fc07a856d6eb57f735368b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('normalizer', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__C': array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,  1.1,\n",
       "        1.2]), 'clf__kernel': ['linear', 'rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_grid = GridSearchCV(pipeline, param_grid = {\n",
    "    'clf__kernel' : ['linear', 'rbf'],\n",
    "    'clf__C' : np.linspace(0.1,1.2,12)\n",
    "})\n",
    "\n",
    "cv_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1db1c347-3780-44fc-bc61-2d55e382b8b3",
    "_uuid": "e16b269c07f3006514e9cc26f7ed65ea4446eb90"
   },
   "source": [
    "The best combination of the parameters can be accessed from `best_params_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "2d80baea-f7b6-4b0e-a018-c5067d2ca276",
    "_uuid": "7d88e13937855d940b91e2898bda4d4c6dbb5875"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.20000000000000001, 'clf__kernel': 'linear'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=0.20000000000000001, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97777777777777775"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "953cea3d-5702-4059-9be3-61cf682adc1e",
    "_uuid": "b540763bd0533037a6e3e79ed46f3321593e6f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after CV is 95.000%\n"
     ]
    }
   ],
   "source": [
    "y_predict = cv_grid.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_predict)\n",
    "print('Accuracy of Logistic Regression after CV is %.3f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "540b0434-df37-4d5d-8426-87e450b132d5",
    "_uuid": "f3cd900d545af249fdb97b41e095e7ddfcc78eb6"
   },
   "source": [
    "I'll revisit and make improvements to the pipeline in the future, kindly provide reviews and suggestions to improve this process.\n",
    "\n",
    "IMPROVEMENTS\n",
    "\n",
    "- I've added cross validation by using kFolds at each step, to get more meaningfull results.\n",
    "- Initially, I made the rookie mistake of checking the accuracy with the test dataset for each classifier. By using KFolds I've essentially created and used a validation dataset and saved the test dataset to score the best model\n",
    "- If the results are really accurate, it's a good idea to tweak the train test split, to get more test data\n",
    "\n",
    "\n",
    "Kindly upvote if you've found this notebook useful :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
